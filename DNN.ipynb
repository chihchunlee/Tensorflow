{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 基礎資料集\n",
    "深度學習的 helloworld\n",
    "0~9黑白照的資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 使用\n",
    "MNIST is a computer vision dataset. It consists of black and white images from zero to nine. Each image is 28 * 28 and have been flatten to 784 dimension vector. Also, it includes labels for each image, telling us which digit it is.\n",
    "\n",
    "![Alt text](./images/dnn_implement/Selection_017.png)\n",
    "![Alt text](./images/dnn_implement/Selection_018.png)\n",
    "\n",
    "\n",
    "The MNIST data is split into three parts: \n",
    "1. 55000 training data (mnist.train) with a shape of [55000, 784]\n",
    "2. 10000 test data (mnist.test) with a shape of [10000, 784]\n",
    "3. 5000 validation data (mnist.validation) with a shape of [5000, 784]\n",
    "\n",
    "you can access:  \n",
    "training image as `mnist.train.images` (see below picture)  \n",
    "training label as `mnist.train.labels` (see below picture)  \n",
    "test image as `mnist.test.images`   \n",
    "test label as `mnist.test.labels`   \n",
    "\n",
    "Note that label is encoded as \"one-hot vectors\", which mean if the target image is 2, the label should be [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "![Alt text](./images/dnn_implement/Selection_021.png)\n",
    "![Alt text](./images/dnn_implement/Selection_020.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist.train.next_batch(5)去訓練資料抓5張\n",
    "print(batch_ys.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(batch_xs[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "first 5 labels [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]:\n",
      "\n",
      "first 5 images [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]:\n",
      "\n",
      "(5, 10)\n",
      "(5, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9fa5629990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Load mnist dataset\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(5)\n",
    "\n",
    "print('first 5 labels {}:\\n'.format(batch_ys))\n",
    "print('first 5 images {}:\\n'.format(batch_xs))\n",
    "print(batch_ys.shape)\n",
    "print(batch_xs.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(batch_xs[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) 一次丟N張的照片 none 每張是784向量\n",
    "y = tf.placeholder(tf.float32, [None, 10]) 一次丟N張的照片 10是one-hot-encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立簡單模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "[[-1.4334959  -0.76011515 -1.3327067  -0.09457059 -0.01114367 -0.16859426\n",
      "   0.952611    0.10942791 -1.2817466  -0.7826921 ]\n",
      " [ 0.01969196  0.29250538  0.5686713   0.21260937 -1.3440645   0.3973139\n",
      "   0.09042579 -0.42369497 -0.06636701 -1.0330623 ]\n",
      " [ 1.7785219   0.7757135   0.15933594 -0.19476564 -0.22079286  0.94446707\n",
      "   0.32802245 -0.26924878 -0.7887764  -0.01541788]\n",
      " [ 1.0788614  -0.03137057 -0.8063443  -0.19644739  0.8241819   0.1460176\n",
      "  -0.23344086  0.01601024 -1.7146298  -0.29485235]\n",
      " [ 1.1814967   0.24996424 -0.3956877   0.45606297 -0.5989076   0.7897457\n",
      "   0.39256778  0.14799078 -1.1777437   0.13037804]]\n",
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Load mnist dataset\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# Define image input 784 = 28 * 28. Note that DNN input is a vector\n",
    "# [None, 784] mean that there are a batch of data and each of them is 784 dimension vector\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# Define label. There are totally 10 class (0-9)\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([784, 10], stddev=0.1))\n",
    "b = tf.Variable(tf.truncated_normal([10], stddev=0.1))\n",
    "y_predict = tf.matmul(x, W) + b\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(5)\n",
    "        \n",
    "    y_predict_ = sess.run(y_predict, feed_dict={x: batch_xs, y: batch_ys})\n",
    "    print(y_predict_)\n",
    "    print(y_predict_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立DNN神經網路模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "[[0.00537947 0.07978871 0.         0.         0.03151332 0.27973643\n",
      "  0.04589504 0.         0.5698735  0.        ]\n",
      " [0.         0.         0.         0.         0.4519012  0.52777255\n",
      "  0.228033   0.         0.25697675 0.        ]\n",
      " [0.         0.         0.27386382 0.         0.09030299 0.27049312\n",
      "  0.00587577 0.         0.4377197  0.        ]\n",
      " [0.         0.25621703 0.0647132  0.         0.         0.5529596\n",
      "  0.26548126 0.14872824 0.28003764 0.        ]\n",
      " [0.         0.04047399 0.43868217 0.         0.         0.18563145\n",
      "  0.05248273 0.         0.40567395 0.02477902]]\n",
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "INPUT_NODE =784\n",
    "\n",
    "LAYER1_NODE = 128\n",
    "LAYER2_NODE = 64\n",
    "LAYER3_NODE = 10\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "b1 = tf.Variable(tf.truncated_normal([LAYER1_NODE], stddev=0.1))\n",
    "W2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, LAYER2_NODE], stddev=0.1))\n",
    "b2 = tf.Variable(tf.truncated_normal([LAYER2_NODE], stddev=0.1))\n",
    "W3 = tf.Variable(tf.truncated_normal([LAYER2_NODE, LAYER3_NODE], stddev=0.1))\n",
    "b3 = tf.Variable(tf.truncated_normal([LAYER3_NODE], stddev=0.1))\n",
    "\n",
    "layer_1 = tf.matmul(x, W1) + b1\n",
    "out1 = tf.nn.relu(layer_1)\n",
    "layer_2 = tf.matmul(out1, W2) + b2\n",
    "out2 = tf.nn.relu(layer_2)\n",
    "layer_3 = tf.matmul(out2, W3) + b3\n",
    "out3 = tf.nn.relu(layer_3)\n",
    "\n",
    "y_predict = out3\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(5)\n",
    "        \n",
    "    y_predict_ = sess.run(y_predict, feed_dict={x: batch_xs, y: batch_ys})\n",
    "    print(y_predict_)\n",
    "    print(y_predict_.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
